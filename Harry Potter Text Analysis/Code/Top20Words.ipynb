{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! sudo pip install nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/training/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the elephants 4 cats\n"
     ]
    }
   ],
   "source": [
    "#** apply lower() and remove punctuation **\n",
    "import re\n",
    "def removePunctuation(text):\n",
    "    \"\"\"Removes punctuation, changes to lowercase, and strips leading and trailing spaces.\n",
    "    Note:\n",
    "        Only spaces, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated. (e.g. it's becomes its)\n",
    "    Args:\n",
    "        text (str): A string.\n",
    "    Returns:\n",
    "        str: The cleaned up string.\n",
    "    \"\"\"\n",
    "    return re.sub('[^a-z| |0-9]', '', text.strip().lower())\n",
    "print removePunctuation(\"The Elephant's 4 cats. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count frequency of words in book 1\n",
    "book1words = sc.textFile(\"file:/home/training/Desktop/Clean Files/HP1.txt\").flatMap(lambda line: line.strip().split(\" \")).filter(lambda x: x != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'one', u'the', u'boy', u'who', u'lived']\n"
     ]
    }
   ],
   "source": [
    "#apply punctuaion & lower function\n",
    "book1words = book1words.map(removePunctuation)\n",
    "#remove punctuation\n",
    "print book1words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book1wordslemmatizer = book1words.map(lambda word: WordNetLemmatizer().lemmatize(str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book1remove = book1wordslemmatizer.filter(lambda word: word not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 1), ('boy', 1), ('lived', 1), ('mr', 1), ('mr', 1)]\n"
     ]
    }
   ],
   "source": [
    "#map to key-value pair\n",
    "book1words_1 = book1remove.map(lambda word : (str(word),1))\n",
    "print book1words_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 852), ('personally', 1), ('yellow', 5), ('sleek', 2), ('four', 34)]\n"
     ]
    }
   ],
   "source": [
    "#reduceByKey() operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets.\n",
    "book1words_1_agg = book1words_1.reduceByKey(lambda a,b : a+b)\n",
    "print book1words_1_agg.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1213, 'harry'), (1186, 'wa'), (852, ''), (794, 'said'), (429, 'ron'), (336, 'hagrid'), (268, 'one'), (264, 'back'), (257, 'hermione'), (209, 'know'), (203, 'get'), (198, 'got'), (195, 'could'), (195, 'like'), (195, 'didnt'), (181, 'see'), (180, 'professor'), (169, 'looked'), (145, 'snape'), (145, 'dont'), (145, 'go')]\n"
     ]
    }
   ],
   "source": [
    "book1words_1_agg_order = book1words_1_agg.map(lambda (a,b): (b,a)).sortByKey(ascending=False)\n",
    "print book1words_1_agg_order.take(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count frequency of words in book 2\n",
    "book2words = sc.textFile(\"file:/home/training/Desktop/Clean Files/HP2.txt\").flatMap(lambda line: line.strip().split(\" \")).filter(lambda x: x != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'one', u'the', u'worst', u'birthday', u'not']\n"
     ]
    }
   ],
   "source": [
    "#apply punctuaion & lower function\n",
    "book2words = book2words.map(removePunctuation)\n",
    "#remove punctuation\n",
    "print book2words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book2wordslemmatizer = book2words.map(lambda word: WordNetLemmatizer().lemmatize(str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book2remove = book2wordslemmatizer.filter(lambda word: word not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 1), ('worst', 1), ('birthday', 1), ('first', 1), ('time', 1)]\n"
     ]
    }
   ],
   "source": [
    "#map to key-value pair\n",
    "book2words_1 = book2remove.map(lambda word : (word,1))\n",
    "print book2words_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 1333), ('yellow', 6), ('four', 26), ('rocketing', 1), ('hanging', 22)]\n"
     ]
    }
   ],
   "source": [
    "#reduceByKey() operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets.\n",
    "book2words_1_agg = book2words_1.reduceByKey(lambda a,b : a+b)\n",
    "print book2words_1_agg.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1508, 'harry'), (1333, ''), (1267, u'wa'), (1212, 'said'), (699, 'ron'), (290, 'hermione'), (281, 'back'), (231, 'mr'), (226, 'one'), (204, 'could'), (203, 'malfoy'), (197, 'lockhart'), (194, 'professor'), (185, 'got'), (180, 'like'), (178, 'know'), (172, 'time'), (171, 'around'), (170, u'eye'), (158, 'go'), (157, 'weasley')]\n"
     ]
    }
   ],
   "source": [
    "book2words_1_agg_order = book2words_1_agg.map(lambda (a,b): (b,a)).sortByKey(ascending=False)\n",
    "print book2words_1_agg_order.take(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count frequency of words in book 3\n",
    "book3words = sc.textFile(\"file:/home/training/Desktop/Clean Files/HP3.txt\").flatMap(lambda line: line.strip().split(\" \")).filter(lambda x: x != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'chapter', u'one', u'owl', u'post', u'harry']\n"
     ]
    }
   ],
   "source": [
    "#apply punctuaion & lower function\n",
    "book3words = book3words.map(removePunctuation)\n",
    "#remove punctuation\n",
    "print book3words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book3wordslemmatizer = book3words.map(lambda word: WordNetLemmatizer().lemmatize(str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book3remove = book3wordslemmatizer.filter(lambda word: word not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chapter', 1), ('one', 1), ('owl', 1), ('post', 1), ('harry', 1)]\n"
     ]
    }
   ],
   "source": [
    "#map to key-value pair\n",
    "book3words_1 = book3remove.map(lambda word : (word,1))\n",
    "print book3words_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 1166), ('raining', 1), ('yellow', 9), ('four', 15), ('clotted', 1)]\n"
     ]
    }
   ],
   "source": [
    "#reduceByKey() operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets.\n",
    "book3words_1_agg = book3words_1.reduceByKey(lambda a,b : a+b)\n",
    "print book3words_1_agg.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1824, 'harry'), (1648, u'wa'), (1436, 'said'), (1166, ''), (754, 'ron'), (603, 'hermione'), (404, 'lupin'), (400, 'professor'), (376, 'black'), (350, 'back'), (288, 'one'), (242, 'like'), (241, 'around'), (235, 'looked'), (226, 'see'), (224, 'could'), (213, 'got'), (206, 'snape'), (206, 'hagrid'), (205, u'eye'), (203, 'know')]\n"
     ]
    }
   ],
   "source": [
    "book3words_1_agg_order = book3words_1_agg.map(lambda (a,b): (b,a)).sortByKey(ascending=False)\n",
    "print book3words_1_agg_order.take(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count frequency of words in book 4\n",
    "book4words = sc.textFile(\"file:/home/training/Desktop/Clean Files/HP4.txt\").flatMap(lambda line: line.strip().split(\" \")).filter(lambda x: x != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'chapter', u'one', u'', u'the', u'riddle']\n"
     ]
    }
   ],
   "source": [
    "#apply punctuaion & lower function\n",
    "book4words = book4words.map(removePunctuation)\n",
    "#remove punctuation\n",
    "print book4words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book4wordslemmatizer = book4words.map(lambda word: WordNetLemmatizer().lemmatize(str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book4remove = book4wordslemmatizer.filter(lambda word: word not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chapter', 1), ('one', 1), ('', 1), ('riddle', 1), ('house', 1)]\n"
     ]
    }
   ],
   "source": [
    "#map to key-value pair\n",
    "book4words_1 = book4remove.map(lambda word : (word,1))\n",
    "print book4words_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 4633), ('yellow', 12), ('four', 56), ('rocketing', 1), ('hanging', 17)]\n"
     ]
    }
   ],
   "source": [
    "#reduceByKey() operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets.\n",
    "book4words_1_agg = book4words_1.reduceByKey(lambda a,b : a+b)\n",
    "print book4words_1_agg.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4633, ''), (2930, 'harry'), (2740, u'wa'), (2632, 'said'), (1044, 'ron'), (825, 'hermione'), (677, 'mr'), (595, 'back'), (530, 'dumbledore'), (508, 'one'), (490, 'around'), (483, 'looked'), (445, 'like'), (444, 'could'), (420, 'though'), (417, 'got'), (400, u'eye'), (400, 'would'), (389, u'know'), (373, 'moody'), (370, 'weasley')]\n"
     ]
    }
   ],
   "source": [
    "book4words_1_agg_order = book4words_1_agg.map(lambda (a,b): (b,a)).sortByKey(ascending=False)\n",
    "print book4words_1_agg_order.take(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count frequency of words in book 5\n",
    "book5words = sc.textFile(\"file:/home/training/Desktop/Clean Files/HP5.txt\").flatMap(lambda line: line.strip().split(\" \")).filter(lambda x: x != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'chapter', u'1', u'', u'the', u'trip']\n"
     ]
    }
   ],
   "source": [
    "#apply punctuaion & lower function\n",
    "book5words = book5words.map(removePunctuation)\n",
    "#remove punctuation\n",
    "print book5words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book5wordslemmatizer = book5words.map(lambda word: WordNetLemmatizer().lemmatize(str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book5remove = book5wordslemmatizer.filter(lambda word: word not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chapter', 1), ('1', 1), ('', 1), ('trip', 1), (u'wa', 1)]\n"
     ]
    }
   ],
   "source": [
    "#map to key-value pair\n",
    "book5words_1 = book5remove.map(lambda word : (word,1))\n",
    "print book5words_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 36), ('raining', 3), ('bakatcha', 3), ('yellow', 26), ('four', 52)]\n"
     ]
    }
   ],
   "source": [
    "#reduceByKey() operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets.\n",
    "book5words_1_agg = book5words_1.reduceByKey(lambda a,b : a+b)\n",
    "print book5words_1_agg.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3570, 'harry'), (2770, u'wa'), (1614, 'said'), (1168, 'ron'), (786, 'hermione'), (607, 'one'), (537, 'back'), (531, 'looked'), (477, 'well'), (473, 'asked'), (463, 'like'), (456, 'yelled'), (434, 'malfoy'), (422, 'professor'), (381, 'time'), (379, 'get'), (375, 'could'), (372, 'wand'), (362, 'would'), (348, u'mr'), (343, 'right')]\n"
     ]
    }
   ],
   "source": [
    "book5words_1_agg_order = book5words_1_agg.map(lambda (a,b): (b,a)).sortByKey(ascending=False)\n",
    "print book5words_1_agg_order.take(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count frequency of words in book 6\n",
    "book6words = sc.textFile(\"file:/home/training/Desktop/Clean Files/HP6.txt\").flatMap(lambda line: line.strip().split(\" \")).filter(lambda x: x != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'chapter', u'1', u'the', u'other', u'minister']\n"
     ]
    }
   ],
   "source": [
    "#apply punctuaion & lower function\n",
    "book6words = book6words.map(removePunctuation)\n",
    "#remove punctuation\n",
    "print book6words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book6wordslemmatizer = book6words.map(lambda word: WordNetLemmatizer().lemmatize(str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book6remove = book6wordslemmatizer.filter(lambda word: word not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chapter', 1), ('1', 1), ('minister', 1), (u'wa', 1), ('nearing', 1)]\n"
     ]
    }
   ],
   "source": [
    "#map to key-value pair\n",
    "book6words_1 = book6remove.map(lambda word : (word,1))\n",
    "print book6words_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 3877), (u'fawn', 1), ('yellow', 12), ('four', 36), ('hanging', 9)]\n"
     ]
    }
   ],
   "source": [
    "#reduceByKey() operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets.\n",
    "book6words_1_agg = book6words_1.reduceByKey(lambda a,b : a+b)\n",
    "print book6words_1_agg.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3877, ''), (2617, 'harry'), (2449, 'said'), (2397, u'wa'), (885, 'dumbledore'), (882, 'ron'), (849, 'page'), (658, 'hermione'), (475, 'could'), (453, 'would'), (421, 'back'), (418, 'one'), (417, 'well'), (392, 'know'), (363, 'like'), (349, 'time'), (347, 'think'), (343, 'slughorn'), (338, 'snape'), (335, 'looked'), (330, 'dont')]\n"
     ]
    }
   ],
   "source": [
    "book6words_1_agg_order = book6words_1_agg.map(lambda (a,b): (b,a)).sortByKey(ascending=False)\n",
    "print book6words_1_agg_order.take(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count frequency of words in book 6\n",
    "book7words = sc.textFile(\"file:/home/training/Desktop/Clean Files/HP7.txt\").flatMap(lambda line: line.strip().split(\" \")).filter(lambda x: x != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'chapter', u'one', u'the', u'dark', u'lord']\n"
     ]
    }
   ],
   "source": [
    "#apply punctuaion & lower function\n",
    "book7words = book7words.map(removePunctuation)\n",
    "#remove punctuation\n",
    "print book7words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book7wordslemmatizer = book7words.map(lambda word: WordNetLemmatizer().lemmatize(str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book7remove = book7wordslemmatizer.filter(lambda word: word not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chapter', 1), ('one', 1), ('dark', 1), ('lord', 1), ('ascending', 1)]\n"
     ]
    }
   ],
   "source": [
    "#map to key-value pair\n",
    "book7words_1 = book7remove.map(lambda word : (word,1))\n",
    "print book7words_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 1774), ('raining', 7), ('yellow', 11), ('four', 37), ('hanging', 21)]\n"
     ]
    }
   ],
   "source": [
    "#reduceByKey() operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets.\n",
    "book7words_1_agg = book7words_1.reduceByKey(lambda a,b : a+b)\n",
    "print book7words_1_agg.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2886, 'harry'), (2779, u'wa'), (1977, 'said'), (1774, ''), (1173, 'ron'), (1111, 'hermione'), (645, u'wand'), (635, 'could'), (539, 'back'), (497, 'know'), (483, 'dumbledore'), (464, 'one'), (458, 'like'), (444, 'would'), (430, 'looked'), (392, u'eye'), (363, 'around'), (360, 'think'), (358, 'voldemort'), (340, 'still'), (337, 'hand')]\n"
     ]
    }
   ],
   "source": [
    "book7words_1_agg_order = book7words_1_agg.map(lambda (a,b): (b,a)).sortByKey(ascending=False)\n",
    "print book7words_1_agg_order.take(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
