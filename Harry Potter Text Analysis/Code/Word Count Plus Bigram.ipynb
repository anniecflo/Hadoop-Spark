{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "#from senti_classifier import senti_classifier\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp1 = sc.textFile(\"file:/home/training/Desktop/HP5.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book1RDD = hp1.map(lambda line: re.split('CHAPTER\\s',line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book1RDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = book1RDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_corpus = list()\n",
    "for i in range(0,38):\n",
    "    word_corpus.append(str(test[0][i].encode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book1RDD = sc.parallelize(word_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentiment(word):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    for sentence in word:\n",
    "        ss= sid.polarity_scores(sentence)\n",
    "        for k in sorted(ss):\n",
    "            print('{1}, '.format(ss[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count for chapter 1 - 5972\n",
      "Word count for chapter 2 - 6260\n",
      "Word count for chapter 3 - 5293\n",
      "Word count for chapter 4 - 5796\n",
      "Word count for chapter 5 - 5476\n",
      "Word count for chapter 6 - 6977\n",
      "Word count for chapter 7 - 4702\n",
      "Word count for chapter 8 - 4334\n",
      "Word count for chapter 9 - 8449\n",
      "Word count for chapter 10 - 6057\n",
      "Word count for chapter 11 - 6082\n",
      "Word count for chapter 12 - 8557\n",
      "Word count for chapter 13 - 9095\n",
      "Word count for chapter 14 - 8370\n",
      "Word count for chapter 15 - 7072\n",
      "Word count for chapter 16 - 6149\n",
      "Word count for chapter 17 - 6810\n",
      "Word count for chapter 18 - 7190\n",
      "Word count for chapter 19 - 6955\n",
      "Word count for chapter 20 - 6641\n",
      "Word count for chapter 21 - 7728\n",
      "Word count for chapter 22 - 8257\n",
      "Word count for chapter 23 - 7667\n",
      "Word count for chapter 24 - 8362\n",
      "Word count for chapter 25 - 8354\n",
      "Word count for chapter 26 - 8928\n",
      "Word count for chapter 27 - 7674\n",
      "Word count for chapter 28 - 8302\n",
      "Word count for chapter 29 - 7655\n",
      "Word count for chapter 30 - 8557\n",
      "Word count for chapter 31 - 8210\n",
      "Word count for chapter 32 - 6543\n",
      "Word count for chapter 33 - 3939\n",
      "Word count for chapter 34 - 5348\n",
      "Word count for chapter 35 - 8008\n",
      "Word count for chapter 36 - 4029\n",
      "Word count for chapter 37 - 8403\n",
      "Word count for chapter 38 - 7938\n"
     ]
    }
   ],
   "source": [
    "oneRDD = book1RDD.collect()\n",
    "i = 1\n",
    "for item in oneRDD:\n",
    "    print(\"Word count for chapter {} - {}\".format(i, len(item.split())))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: The polarity is:0.107235897717\n",
      "Chapter 2: The polarity is:0.0441296518477\n",
      "Chapter 3: The polarity is:0.0506001578271\n",
      "Chapter 4: The polarity is:0.0640941837328\n",
      "Chapter 5: The polarity is:0.0548952796252\n",
      "Chapter 6: The polarity is:0.0604739047707\n",
      "Chapter 7: The polarity is:0.0613165841573\n",
      "Chapter 8: The polarity is:0.0637373626622\n",
      "Chapter 9: The polarity is:0.0618598118639\n",
      "Chapter 10: The polarity is:0.0542938317761\n",
      "Chapter 11: The polarity is:0.0511414470719\n",
      "Chapter 12: The polarity is:0.0503030758519\n",
      "Chapter 13: The polarity is:0.0487875054626\n",
      "Chapter 14: The polarity is:0.0466005709382\n",
      "Chapter 15: The polarity is:0.0444610544916\n",
      "Chapter 16: The polarity is:0.0434803673969\n",
      "Chapter 17: The polarity is:0.043390712065\n"
     ]
    }
   ],
   "source": [
    "for chapter in range(1,book1RDD.count()+1):\n",
    "    testimonial = TextBlob(str(book1RDD.take(chapter)))\n",
    "    print(\"Chapter {}: The polarity is:{}\".format(chapter,testimonial.sentiment.polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: The Subjectivity is:0.486919267469\n",
      "Chapter 2: The Subjectivity is:0.477081046434\n",
      "Chapter 3: The Subjectivity is:0.462337101336\n",
      "Chapter 4: The Subjectivity is:0.48016922028\n",
      "Chapter 5: The Subjectivity is:0.486131004085\n",
      "Chapter 6: The Subjectivity is:0.471500111664\n",
      "Chapter 7: The Subjectivity is:0.472537715987\n",
      "Chapter 8: The Subjectivity is:0.474823787546\n",
      "Chapter 9: The Subjectivity is:0.474243029188\n",
      "Chapter 10: The Subjectivity is:0.475059651406\n",
      "Chapter 11: The Subjectivity is:0.47583170769\n",
      "Chapter 12: The Subjectivity is:0.474051054869\n",
      "Chapter 13: The Subjectivity is:0.473377548682\n",
      "Chapter 14: The Subjectivity is:0.472455413649\n",
      "Chapter 15: The Subjectivity is:0.472846493106\n",
      "Chapter 16: The Subjectivity is:0.474637351779\n",
      "Chapter 17: The Subjectivity is:0.476261586719\n"
     ]
    }
   ],
   "source": [
    "for chapter in range(1,book1RDD.count()+1):\n",
    "    testimonial = TextBlob(str(book1RDD.take(chapter)))\n",
    "    print(\"Chapter {}: The Subjectivity is:{}\".format(chapter,testimonial.sentiment.subjectivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abc = book1RDD.map(lambda x: x.split('.')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = abc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "for item in output:\n",
    "    for x in item:\n",
    "        words = x.split(\" \")\n",
    "        for word in words: \n",
    "            if len(word.strip()) > 0:\n",
    "                a.append(word.rstrip().lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordlistRDD = sc.parallelize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanwordRDD = wordlistRDD.map(lambda z:re.sub(r'[^\\s\\w]','',z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/training/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/training/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "removedstopwordsRDD = cleanwordRDD.filter(lambda word: word not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(removedstopwordsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xyz = list()\n",
    "for item in removedstopwordsRDD.collect():\n",
    "    xyz.append(item.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgs = nltk.bigrams(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(bgs)\n",
    "#for k,v in fdist.items():\n",
    "#    print (k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('privet', 'drive'), 24)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(fdist.items()).filter(lambda line: str(line[0][0]) not in ('said','','i') and str(line[0][0]) == 'privet').takeOrdered(20, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('diagon', 'alley'), 7)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(fdist.items()).filter(lambda line: str(line[0][0]) not in ('said','','i') and str(line[0][0]) == 'diagon').takeOrdered(20, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('grimmauld', 'place'), 36)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(fdist.items()).filter(lambda line: str(line[0][0]) not in ('said','','i') and str(line[0][0]) == 'grimmauld').takeOrdered(20, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('expecto', 'patronum'), 4)]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(fdist.items()).filter(lambda line: str(line[0][0]) not in ('said','','i') and str(line[0][0]) == 'expecto').takeOrdered(20, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('harry', 'ron'), 92),\n",
       " (('professor', 'mcgonagall'), 79),\n",
       " (('harry', 'potter'), 77),\n",
       " (('ron', 'hermione'), 55),\n",
       " (('harry', 'said'), 54),\n",
       " (('mrs', 'weasley'), 52),\n",
       " (('mr', 'weasley'), 48),\n",
       " (('fred', 'george'), 44),\n",
       " (('chamber', 'secrets'), 42),\n",
       " (('mr', 'malfoy'), 41),\n",
       " (('harry', 'could'), 38),\n",
       " (('uncle', 'vernon'), 34),\n",
       " (('harry', 'looked'), 33),\n",
       " (('nearly', 'headless'), 33),\n",
       " (('headless', 'nick'), 31),\n",
       " (('madam', 'pomfrey'), 28),\n",
       " (('gilderoy', 'lockhart'), 28),\n",
       " (('could', 'see'), 27),\n",
       " (('harry', ''), 27),\n",
       " (('ive', 'got'), 26)]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(fdist.items()).filter(lambda line: str(line[0][0]) not in ('said','','i')).takeOrdered(20, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from senti_classifier import senti_classifier\n",
    "sentences = ['The movie was the worst movie', 'It was the worst acting by the actors']\n",
    "pos_score, neg_score = senti_classifier.polarity_scores(sentences)\n",
    "print pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
